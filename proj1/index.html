<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <style>
    body {
      padding: 100px;
      width: 1000px;
      margin: auto;
      text-align: left;
      font-weight: 300;
      font-family: 'Open Sans', sans-serif;
      color: #121212;
    }

    h1,
    h2,
    h3,
    h4 {
      font-family: 'Source Sans Pro', sans-serif;
    }
  </style>
  <title>CS 284A Rasterizer</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

  <h1 align="middle">CS 284A: Computer Graphics and Imaging, Spring 2022</h1>
  <h1 align="middle">Project 1: Rasterizer</h1>
  <h2 align="middle">Juntao Peng, Yang Huang, CS184-sigsegv</h2>

  <br><br>

  <div>

    <h2 align="middle">Overview</h2>
    <p>In this project we've built a rasterization pipeline for simple triangle. On the basis of triangle, we can render
      a variety of other shapes defined in our SVG input.
      In task 1, we built a simple rasterizer for triangle.
      In task 2, we added supersampling, an anti-aliasing technique for rasterization.
      In task 3, we performed layered transform on a robot SVG.
      In task 4, we implemented a barycentric interpolation algorithm which can be used in either color or later uv
      coordinates.
      In task 5, we implemented pixel sampling on textures, including nearest and bilinear sampling.
      In task 6, we implemented level sampling on mipmap.
    </p>

    <p>
      Click <a href="https://cal-cs184-student.github.io/sp22-project-webpages-UncooleBen/proj1/index.html">here</a> for
      GitHub pages.
    </p>
    <h2 align="middle">Section I: Rasterization</h2>

    <h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

    <!--
Walk through how you rasterize triangles in your own words.
Explain how your algorithm is no worse than one that checks each sample within the bounding box of the triangle.
Show a png screenshot of basic/test4.svg with the default viewing parameters and with the pixel inspector centered on an interesting part of the scene.
Extra credit: Explain any special optimizations you did beyond simple bounding box triangle rasterization, 
with a timing comparison table (we suggest using the c++ clock() function around the svg.draw() command in DrawRend::redraw() 
to compare millisecond timings with your various optimizations off and on).
-->

    <p>
      We use min and max function to compute the left, right, up, and down bounding lines of given triangle.
      This saves us from iterating every pixel in the screen space. Therefore, our algorithm is no worse than one that
      checks each sample within the bounding box of the triangle.
    </p>
    <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/task1.png" align="middle" width="400px" />
            <figcaption align="middle">test4.svg</figcaption>
          </td>
        </tr>
      </table>
    </div>

    <p>
      As you can see, one interesting point of the vanilla triangle rasterization algorithm is that there is severe
      aliasing on certain tip of our triangle.
    </p>

    <h3 align="middle">Part 2: Antialiasing triangles</h3>

    <!--
Walk through your supersampling algorithm and data structures. 
Why is supersampling useful? 
What modifications did you make to the rasterization pipeline in the process? 
Explain how you used supersampling to antialias your triangles.
Show png screenshots of basic/test4.svg with the default viewing parameters and sample rates 1, 4, and 16 to compare them side-by-side. 
Position the pixel inspector over an area that showcases the effect dramatically; for example, a very skinny triangle corner. 
Explain why these results are observed.
Extra credit: If you implemented alternative antialiasing methods, describe them and include comparison pictures demonstrating the difference between your method and grid-based supersampling.
-->

    <h3 align="middle">Part 3: Transforms</h3>

    <!--
  Create an updated version of svg/transforms/robot.svg with cubeman doing something more interesting, 
  like waving or running. Feel free to change his colors or proportions to suit your creativity. 
  Save your svg file as my_robot.svg in your docs/ directory and show a png screenshot of your rendered drawing in your write-up. 
  Explain what you were trying to do with cubeman in words.
-->

    <h2 align="middle">Section II: Sampling</h2>

    <h3 align="middle">Part 4: Barycentric coordinates</h3>

    <!--
Explain barycentric coordinates in your own words and use an image to aid you in your explanation. 
One idea is to use a svg file that plots a single triangle with one red, one green, and one blue vertex, 
which should produce a smoothly blended color triangle.
Show a png screenshot of svg/basic/test7.svg with default viewing parameters and sample rate 1.
If you make any additional images with color gradients, include them.
-->

    <h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

    <!--
Explain pixel sampling in your own words and describe how you implemented it to perform texture mapping. 
Briefly discuss the two different pixel sampling methods, nearest and bilinear.
Check out the svg files in the svg/texmap/ directory. 
Use the pixel inspector to find a good example of where bilinear sampling clearly defeats nearest sampling. 
Show and compare four png screenshots using 
nearest sampling at 1 sample per pixel, nearest sampling at 16 samples per pixel, bilinear sampling at 1 sample per pixel, and bilinear sampling at 16 samples per pixel.
Comment on the relative differences. Discuss when there will be a large difference between the two methods and why.
-->
    <p>
      Pixel sampling is finding the color of a pixel by figuring out a mapping from xy coordinates in pixel space
      to uv coordinates in texel space. However, since texel space is discrete, the barycentric uv coordinates computed
      from triangle will most likely not
      located on a texel. Therefore, we need pixel sampling method such as nearest and bilinear sampling.
    </p>

    <p>
      In nearest pixel sampling, we compare the distances between the sampled uv coordinates and its four nearest texel
      neighbors.
      And then choose the nearest neighbor's color as the sampled pixel's color. In our implementation, this can be
      simplified as
      rounding the uv coordinates into the nearest integer, avoiding computing four distances.
    </p>

    <p>
      In bilinear sampling, instead of discretely use the nearest texel color as the pixel's color. We perform linear
      interpolations
      among the four nearest texel points. This yields a more continuous color than nearest pixeling. In our
      implementation,
      the linear
      interpolation can be computed by a lerp macro. We first lerp the vertical two pairs of neighbors. Then lerp the
      horizontal previous
      lerp results.
    </p>

    <p>
      Below are two examples showing that bilinear sampling beats nearest sampling.
    </p>

    <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/nearest.png" align="middle" width="400px" />
            <figcaption align="middle">Jaggies in nearest sampling.</figcaption>
          </td>
          <td>
            <img src="images/bilinear.png" align="middle" width="400px" />
            <figcaption align="middle">Continuity in bilinear sampling.</figcaption>
          </td>
        </tr>
        <br>
      </table>
    </div>

    <p>
      Below are four examples of nearest and bilinear sampling with 1 and 16 samples per pixel.
    </p>

    <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/nearest-1.png" align="middle" width="400px" />
            <figcaption align="middle">Nearest pixel sampling with 1 sample per pixel</figcaption>
          </td>
          <td>
            <img src="images/nearest-16.png" align="middle" width="400px" />
            <figcaption align="middle">Nearest pixel sampling with 16 samples per pixel</figcaption>
          </td>
        </tr>
        <br>
        <tr>
          <td>
            <img src="images/bilinear-1.png" align="middle" width="400px" />
            <figcaption align="middle">Bilinear sampling with 1 sample per pixel</figcaption>
          </td>
          <td>
            <img src="images/bilinear-16.png" align="middle" width="400px" />
            <figcaption align="middle">Bilinear sampling with 16 samples per pixel</figcaption>
          </td>
        </tr>
      </table>
    </div>

    <p>
      Under low super sampling rate (e.g. 1 sample per pixel), nearest pixel sampling is worse than bilinear sampling
      since one will observe extensive jaggies in nearest pixel sampling images. The reason behind this is nearest
      sampling
      loses informations by choosing only the nearest texel color.
    </p>

    <p>
      However, when super sampling rate is as high as 16, the difference between nearest and bilinear sampling is
      cancelled
      out by the extensive high underlying resolution of super sampling. But it is meaningful to admit that
      supersampling is
      extremely expensive given that we have to use 16 times more memory and computation power to do this. In
      comparison, bilinear
      sampling, though has a few jaggie parts, requires far less memory and computation power.
    </p>

    <p>
      Despite the little difference between nearest and bilinear sampling under supersampling with 16 subpixels, we can
      still observe
      some minor changes between this two images. It is like the "blur then sample" and "sample then blur" discussion in
      the supersampling
      lecture. Nearest pixel sampling with high supersampling is like the "sample then blur" case, whereas bilinear
      sampling with supersampling
      is like the "blur then sample" case. And one would almost always prefer the latter one.
    </p>

    <h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

    <!--
Explain level sampling in your own words and describe how you implemented it for texture mapping.
You can now adjust your sampling technique by selecting pixel sampling, level sampling, or the number of samples per pixel. 
Describe the tradeoffs between speed, memory usage, and antialiasing power between the three various techniques.
Using a png file you find yourself, show us four versions of the image, 
using the combinations of L_ZERO and P_NEAREST, L_ZERO and P_LINEAR, L_NEAREST and P_NEAREST, as well as L_NEAREST and P_LINEAR.
To use your own png, make a copy of one of the existing svg files in svg/texmap/ (or create your own modelled after one of the provided svg files). 
Then, near the top of the file, change the texture filename to point to your own png. 
From there, you can run ./draw and pass in that svg file to render it and then save a screenshot of your results.
Note: Choose a png that showcases the different sampling effects well. 
You may also want to zoom in/out, use the pixel inspector, etc. to demonstrate the differences.
Extra credit: If you implemented any extra filtering methods, describe them and show comparisons between your results with the other above methods.
-->
    <p>
      Level sampling with mipmap is using different texture resolution to color the different scale of pixels. When two
      neighbor screen pixels are
      near in the actual texture space, then we should use low level (high resolution) textures. When two neighbor
      screen pixels are far from each
      other in texture space, then we should use high level (low resolution) textures. This idea comes from the Nyquist
      sampling rate, when the signal
      frequency is higher, as this is often the case of nearer objects in perspective view, we should sample more
      frequently, and vice versa.
    </p>

    <p>
      In our implementation, we use the uv, dy_duv and dx_duv passed in the SampleParams parameter to first compute the
      correct
      float level of the mipmap.
      Then, according to the level sampling parameter, choose the corresponding zero, nearest, or linear interpolation
      method to compute the discrete mipmap level.
      Finally, as in task 5, we call sample_nearest or sample_bilinear method with the chosen mipmap to perform the
      actual sampling.
    </p>

    <p>
      Supersampling is the theoretically best anti-aliasing algorithm because it samples the signal in a higher
      frequency,
      then perform an average. However, supersampling is slow and memory consuming because it has to compute and store
      the
      extra subpixels before averaging them out. On the contrary, pixel sampling is memory efficient and less intensive
      in
      computation because it blurs the output using existing pixels instead of enormous subpixels. However, pixel
      sampling
      cannot distinguish the texture difference that our human eyes preceive between near and far objects. This is where
      level
      sampling is useful. Level sampling with mipmap uses only 33% more memory but can achieve different blurring
      levels. Thus,
      it has better anti-aliasing effect than ordinary pixel sampling. The combination of bilinear pixel sampling and
      linear
      level sampling is called trilinear sampling. Trilinear sampling can achieve almost comparable anti-aliasing result
      as
      supersampling but using much less computation power and memory.
    </p>

    <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/checkerboard.png" align="middle" width="400" />
            <figcaption align="middle">Black-white checkerboard texture</figcaption>
          </td>
        </tr>
      </table>
    </div>

    <div align="middle" style="margin-left: -25%">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/lzeropnearest.png" align="middle" width="700px" />
            <figcaption align="middle">L_ZERO P_NEAREST</figcaption>
          </td>
          <td>
            <img src="images/lzeroplinear.png" align="middle" width="700px" />
            <figcaption align="middle">L_ZERO P_LINEAR</figcaption>
          </td>
        </tr>
        <br>
        <tr>
          <td>
            <img src="images/lnearestpnearest.png" align="middle" width="700px" />
            <figcaption align="middle">L_NEAREST P_NEAREST</figcaption>
          </td>
          <td>
            <img src="images/lnearestplinear.png" align="middle" width="700px" />
            <figcaption align="middle">L_NEAREST P_LINEAR</figcaption>
          </td>
        </tr>
        <tr>
          <td>
            <img src="images/llinearpnearest.png" align="middle" width="700px" />
            <figcaption align="middle">L_LINEAR P_NEAREST</figcaption>
          </td>
          <td>
            <img src="images/llinearplinear.png" align="middle" width="700px" />
            <figcaption align="middle">L_LINEAR P_LINEAR</figcaption>
          </td>
        </tr>
      </table>
    </div>

    <p>
      When using zero level sampling, there is still some moire patterns in these two figures. The only difference lies
      in the edge of the black squares. When using bilinear pixel sampling, the edge is smoother.
    </p>

    <p>
      When using nearest level sampling, we observe that there is much less moire pattern in these two figures. However,
      there is still a black X-shape pattern in the center of both figures. Using bilinear pixel sampling with nearest level
      sampling, can reduce the moire pattern (from left and right comparison).
    </p>

    <p>
      When using linear level sampling, we obeserve that there is even less moire patten in both figures. Moreover, the X-shape
      pattern is gone when using linear level sampling. The right figure is trilinear sampling, it looks like an almost ideal 
      image in the real world. The only problem is that to remove the X-shape black pattern in the center, we have to make the 
      center somehow blurrier. This is a tradeoff between image resolution and anti-aliasing.
    </p>

    <h2 align="middle">Section III: Art Competition</h2>
    <p>If you are not participating in the optional art competition, don't worry about this section!</p>

    <h3 align="middle">Part 7: Draw something interesting!</h3>

</body>

</html>